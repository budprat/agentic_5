{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google ADK Interactive Testing Notebook\n",
    "\n",
    "This notebook allows you to interactively test Google ADK agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure API key\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if not google_api_key:\n",
    "    print(\"❌ Error: GOOGLE_API_KEY not found in environment\")\n",
    "else:\n",
    "    os.environ['GOOGLE_API_KEY'] = google_api_key\n",
    "    print(\"✅ GOOGLE_API_KEY loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ADK components\n",
    "from google.adk import Runner\n",
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LlmAgent\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Chat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chat agent\n",
    "simple_agent = Agent(\n",
    "    name=\"assistant\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"A helpful AI assistant\",\n",
    "    instruction=\"\"\"You are a helpful, friendly AI assistant. \n",
    "    Provide clear and concise responses.\"\"\"\n",
    ")\n",
    "\n",
    "# Create session for simple agent\n",
    "session_service = InMemorySessionService()\n",
    "simple_runner = Runner(\n",
    "    agent=simple_agent,\n",
    "    app_name=\"notebook_test\",\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "simple_session = session_service.create_session(\n",
    "    app_name=\"notebook_test\",\n",
    "    user_id=\"notebook_user\",\n",
    "    session_id=\"simple_chat\"\n",
    ")\n",
    "\n",
    "print(\"✅ Simple chat agent ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with simple agent\n",
    "async def chat_simple(message: str):\n",
    "    content = types.Content(role='user', parts=[types.Part(text=message)])\n",
    "    \n",
    "    response_text = \"\"\n",
    "    async for event in simple_runner.run_async(\n",
    "        user_id=\"notebook_user\",\n",
    "        session_id=simple_session.id,\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                response_text = '\\n'.join([p.text for p in event.content.parts if p.text])\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "# Example usage\n",
    "response = await chat_simple(\"Hello! Can you explain what Google ADK is?\")\n",
    "display(Markdown(f\"**Response:** {response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequential Agent (Research + Writing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential agent with research and writing sub-agents\n",
    "research_agent = Agent(\n",
    "    name=\"researcher\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"Research specialist\",\n",
    "    instruction=\"\"\"You are a research specialist. \n",
    "    Provide key facts and insights about the given topic.\"\"\"\n",
    ")\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"writer\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"Content writer\",\n",
    "    instruction=\"\"\"You are a creative writer. \n",
    "    Take the research and craft it into engaging content.\"\"\"\n",
    ")\n",
    "\n",
    "sequential_agent = SequentialAgent(\n",
    "    name=\"research_writer\",\n",
    "    sub_agents=[research_agent, writer_agent],\n",
    "    description=\"Research and writing team\"\n",
    ")\n",
    "\n",
    "# Create runner for sequential agent\n",
    "seq_runner = Runner(\n",
    "    agent=sequential_agent,\n",
    "    app_name=\"notebook_test\",\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "seq_session = session_service.create_session(\n",
    "    app_name=\"notebook_test\",\n",
    "    user_id=\"notebook_user\",\n",
    "    session_id=\"sequential_chat\"\n",
    ")\n",
    "\n",
    "print(\"✅ Sequential agent ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sequential agent\n",
    "async def research_and_write(topic: str):\n",
    "    content = types.Content(role='user', parts=[types.Part(text=topic)])\n",
    "    \n",
    "    response_text = \"\"\n",
    "    async for event in seq_runner.run_async(\n",
    "        user_id=\"notebook_user\",\n",
    "        session_id=seq_session.id,\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                response_text = '\\n'.join([p.text for p in event.content.parts if p.text])\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "# Example usage\n",
    "article = await research_and_write(\"The future of renewable energy\")\n",
    "display(Markdown(f\"**Article:**\\n\\n{article}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Structured Output Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structured output schema\n",
    "class AnalysisResult(BaseModel):\n",
    "    summary: str = Field(description=\"Brief summary\")\n",
    "    key_points: list[str] = Field(description=\"Main points\")\n",
    "    pros: list[str] = Field(description=\"Advantages\")\n",
    "    cons: list[str] = Field(description=\"Disadvantages\")\n",
    "    recommendation: str = Field(description=\"Final recommendation\")\n",
    "\n",
    "# Create structured output agent\n",
    "structured_agent = LlmAgent(\n",
    "    name=\"analyst\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"\"\"Analyze topics and provide structured insights.\n",
    "    Always provide balanced analysis.\"\"\",\n",
    "    output_schema=AnalysisResult,\n",
    "    output_key=\"analysis\"\n",
    ")\n",
    "\n",
    "# Create runner\n",
    "struct_runner = Runner(\n",
    "    agent=structured_agent,\n",
    "    app_name=\"notebook_test\",\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "struct_session = session_service.create_session(\n",
    "    app_name=\"notebook_test\",\n",
    "    user_id=\"notebook_user\",\n",
    "    session_id=\"structured_chat\"\n",
    ")\n",
    "\n",
    "print(\"✅ Structured agent ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze with structured output\n",
    "import json\n",
    "\n",
    "async def analyze_topic(topic: str):\n",
    "    content = types.Content(role='user', parts=[types.Part(text=f\"Analyze: {topic}\")])\n",
    "    \n",
    "    response_text = \"\"\n",
    "    async for event in struct_runner.run_async(\n",
    "        user_id=\"notebook_user\",\n",
    "        session_id=struct_session.id,\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                response_text = '\\n'.join([p.text for p in event.content.parts if p.text])\n",
    "    \n",
    "    # Parse JSON response\n",
    "    try:\n",
    "        analysis = json.loads(response_text)\n",
    "        return analysis\n",
    "    except:\n",
    "        return {\"error\": \"Could not parse response\", \"raw\": response_text}\n",
    "\n",
    "# Example usage\n",
    "analysis = await analyze_topic(\"Working from home vs office work\")\n",
    "\n",
    "# Display formatted results\n",
    "if \"error\" not in analysis:\n",
    "    display(Markdown(f\"### Summary\\n{analysis['summary']}\"))\n",
    "    display(Markdown(f\"\\n### Key Points\\n\" + \"\\n\".join([f\"- {p}\" for p in analysis['key_points']])))\n",
    "    display(Markdown(f\"\\n### Pros\\n\" + \"\\n\".join([f\"✅ {p}\" for p in analysis['pros']])))\n",
    "    display(Markdown(f\"\\n### Cons\\n\" + \"\\n\".join([f\"❌ {c}\" for c in analysis['cons']])))\n",
    "    display(Markdown(f\"\\n### Recommendation\\n{analysis['recommendation']}\"))\n",
    "else:\n",
    "    print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Chat Cell\n",
    "\n",
    "Use this cell to have ongoing conversations with any agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat function\n",
    "def create_chat_widget(agent_runner, session):\n",
    "    from ipywidgets import widgets, Layout\n",
    "    from IPython.display import display, clear_output\n",
    "    \n",
    "    # Create widgets\n",
    "    chat_output = widgets.Output()\n",
    "    message_input = widgets.Text(\n",
    "        placeholder='Type your message here...',\n",
    "        layout=Layout(width='70%')\n",
    "    )\n",
    "    send_button = widgets.Button(\n",
    "        description='Send',\n",
    "        button_style='primary',\n",
    "        layout=Layout(width='20%')\n",
    "    )\n",
    "    clear_button = widgets.Button(\n",
    "        description='Clear',\n",
    "        button_style='warning',\n",
    "        layout=Layout(width='10%')\n",
    "    )\n",
    "    \n",
    "    # Chat history\n",
    "    chat_history = []\n",
    "    \n",
    "    async def send_message(_):\n",
    "        message = message_input.value\n",
    "        if not message:\n",
    "            return\n",
    "        \n",
    "        # Clear input\n",
    "        message_input.value = ''\n",
    "        \n",
    "        # Add to history\n",
    "        chat_history.append(f\"**You:** {message}\")\n",
    "        \n",
    "        # Get response\n",
    "        content = types.Content(role='user', parts=[types.Part(text=message)])\n",
    "        \n",
    "        response_text = \"\"\n",
    "        async for event in agent_runner.run_async(\n",
    "            user_id=\"notebook_user\",\n",
    "            session_id=session.id,\n",
    "            new_message=content\n",
    "        ):\n",
    "            if event.is_final_response():\n",
    "                if event.content and event.content.parts:\n",
    "                    response_text = '\\n'.join([p.text for p in event.content.parts if p.text])\n",
    "        \n",
    "        chat_history.append(f\"**Agent:** {response_text}\")\n",
    "        \n",
    "        # Update display\n",
    "        with chat_output:\n",
    "            clear_output()\n",
    "            for msg in chat_history:\n",
    "                display(Markdown(msg + \"\\n\\n---\\n\"))\n",
    "    \n",
    "    def clear_chat(_):\n",
    "        chat_history.clear()\n",
    "        with chat_output:\n",
    "            clear_output()\n",
    "    \n",
    "    # Connect buttons\n",
    "    send_button.on_click(lambda _: asyncio.create_task(send_message(_)))\n",
    "    message_input.on_submit(lambda _: asyncio.create_task(send_message(_)))\n",
    "    clear_button.on_click(clear_chat)\n",
    "    \n",
    "    # Display widgets\n",
    "    display(chat_output)\n",
    "    display(widgets.HBox([message_input, send_button, clear_button]))\n",
    "\n",
    "# Create chat widget for simple agent\n",
    "print(\"💬 Chat with the Simple Agent:\")\n",
    "create_chat_widget(simple_runner, simple_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Your Own Agent\n",
    "\n",
    "Create and test your own custom agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own agent here\n",
    "my_agent = Agent(\n",
    "    name=\"my_custom_agent\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"My custom agent\",\n",
    "    instruction=\"\"\"[Replace this with your custom instructions]\n",
    "    \n",
    "    Example: You are an expert in [domain]. \n",
    "    Help users with [specific tasks].\n",
    "    Always [specific behavior].\"\"\"\n",
    ")\n",
    "\n",
    "# Create runner\n",
    "my_runner = Runner(\n",
    "    agent=my_agent,\n",
    "    app_name=\"notebook_test\",\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "my_session = session_service.create_session(\n",
    "    app_name=\"notebook_test\",\n",
    "    user_id=\"notebook_user\",\n",
    "    session_id=\"my_agent_chat\"\n",
    ")\n",
    "\n",
    "# Test it\n",
    "async def test_my_agent(message: str):\n",
    "    content = types.Content(role='user', parts=[types.Part(text=message)])\n",
    "    \n",
    "    response_text = \"\"\n",
    "    async for event in my_runner.run_async(\n",
    "        user_id=\"notebook_user\",\n",
    "        session_id=my_session.id,\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                response_text = '\\n'.join([p.text for p in event.content.parts if p.text])\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "# Test your agent\n",
    "response = await test_my_agent(\"Hello! What can you help me with?\")\n",
    "display(Markdown(f\"**Response:** {response}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}